# -*- coding: utf-8 -*-
"""ClasificadorIluminacion.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1x0vsuyCMWuJfXAFI23rDyK9VkLuQ4SYi
"""

# @title Celda 1: Configuración del Entorno y Librerías

# Instalar librerías necesarias
# TensorFlow ya incluye Keras y muchas dependencias
!pip install tensorflow numpy matplotlib Pillow

import tensorflow as tf
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout
import os
import json
import matplotlib.pyplot as plt
import numpy as np
from PIL import Image # Para visualizar imágenes

print("Librerías instaladas y cargadas.")
print("TensorFlow versión:", tf.__version__)

# @title Celda 2: Preparación del Dataset y Definición de Rutas

# --- CONFIGURACIÓN DE RUTAS ---
# Ajusta esta ruta a donde se encuentre tu carpeta "Agrupados" en Google Drive.
DATASET_BASE_PATH = "C:/Users/59174/Desktop/Agrupados"

# Asegurarse de que la carpeta exista
if not os.path.exists(DATASET_BASE_PATH):
    raise FileNotFoundError(f"La carpeta del dataset no se encontró en: {DATASET_BASE_PATH}\n"
                            "Por favor, verifica la ruta o asegúrate de que el dataset esté subido/montado.")
else:
    print(f"Carpeta del dataset verificada: {DATASET_BASE_PATH}")

# Rutas de salida para el modelo y el mapeo de clases
# Se guardarán en el entorno de Colab por defecto.
# Si quieres guardar en Google Drive, cambia estas rutas:
# Ejemplo para Drive:
MODEL_SAVE_PATH = "C:/Users/59174/Desktop/lighting_classifier_model.h5"
CLASS_MAPPING_FILE = "C:/Users/59174/Desktop/class_mapping.json"

print("Rutas configuradas.")

# @title Celda 3: Exploración de Datos (Visualización de Imágenes de Clases)
import random # <<< ¡CORRECCIÓN: AÑADIR ESTA LÍNEA!
import matplotlib.pyplot as plt
from PIL import Image # Asegurarse que esté importado para Image.open
import os
# --- PARÁMETROS PARA LA VISUALIZACIÓN DE IMÁGENES ---
NUM_IMAGES_TO_DISPLAY = 9
IMAGES_PER_ROW = 3

# Obtener las clases/carpetas
class_folders = [d for d in os.listdir(DATASET_BASE_PATH) if os.path.isdir(os.path.join(DATASET_BASE_PATH, d))]
if not class_folders:
    raise ValueError("No se encontraron subcarpetas (clases) en el DATASET_BASE_PATH.")

# Recopilar rutas de imágenes aleatorias
all_image_paths = []
for folder in class_folders:
    folder_path = os.path.join(DATASET_BASE_PATH, folder)
    images_in_folder = [os.path.join(folder_path, f) for f in os.listdir(folder_path)
                        if f.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.gif'))]
    all_image_paths.extend(images_in_folder)

random.shuffle(all_image_paths)
display_image_paths = all_image_paths[:NUM_IMAGES_TO_DISPLAY]

print(f"Mostrando {len(display_image_paths)} imágenes aleatorias del dataset...")

# Visualización de imágenes
rows = (len(display_image_paths) + IMAGES_PER_ROW - 1) // IMAGES_PER_ROW
plt.figure(figsize=(IMAGES_PER_ROW * 3, rows * 3))

for i, img_path in enumerate(display_image_paths):
    try:
        img = Image.open(img_path)
        plt.subplot(rows, IMAGES_PER_ROW, i + 1)
        plt.imshow(img)
        # Extraer el nombre de la clase de la ruta
        class_name_from_path = os.path.basename(os.path.dirname(img_path))
        plt.title(class_name_from_path)
        plt.axis('off')
    except Exception as e:
        print(f"Error al cargar/mostrar imagen {img_path}: {e}", file=sys.stderr)
        plt.subplot(rows, IMAGES_PER_ROW, i + 1)
        plt.text(0.5, 0.5, "Error", ha='center', va='center', fontsize=12)
        plt.axis('off')

plt.tight_layout()
plt.show()

# Opcional: Mostrar distribución de clases (si se desea)
# Esto requeriría cargar todas las etiquetas, lo cual puede ser lento para un dataset muy grande
# Puedes cargarlo con ImageDataGenerator y ver class_indices.
class_counts = {folder: len([f for f in os.listdir(os.path.join(DATASET_BASE_PATH, folder)) if f.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.gif'))]) for folder in class_folders}
print("\nDistribución de imágenes por clase:")
for cls, count in class_counts.items():
    print(f"- {cls}: {count} imágenes")

# @title Celda 4: Preparación de Datos con ImageDataGenerator

# --- CONFIGURACIÓN DE IMAGEN Y BATCH ---
IMG_HEIGHT, IMG_WIDTH = 128, 128
BATCH_SIZE = 32

# Usaremos ImageDataGenerator para cargar imágenes desde las carpetas
# y aplicar aumentación de datos simple (re-escalado, validación de split)
datagen = ImageDataGenerator(
    rescale=1./255, # Normalizar píxeles a 0-1
    validation_split=0.2 # 20% de los datos para validación
    # Puedes añadir data augmentation aquí si lo deseas para tu presentación
    # rotation_range=20,
    # width_shift_range=0.2,
    # height_shift_range=0.2,
    # horizontal_flip=True,
    # zoom_range=0.2
)

print(f"Cargando datos de entrenamiento desde: {DATASET_BASE_PATH}")
train_generator = datagen.flow_from_directory(
    DATASET_BASE_PATH,
    target_size=(IMG_HEIGHT, IMG_WIDTH),
    batch_size=BATCH_SIZE,
    class_mode='categorical', # Para clasificación multi-clase (one-hot encoding)
    subset='training',
    shuffle=True # Mezclar datos de entrenamiento
)

print(f"Cargando datos de validación desde: {DATASET_BASE_PATH}")
validation_generator = datagen.flow_from_directory(
    DATASET_BASE_PATH,
    target_size=(IMG_HEIGHT, IMG_WIDTH),
    batch_size=BATCH_SIZE,
    class_mode='categorical',
    subset='validation',
    shuffle=False # No mezclar datos de validación
)

num_classes = len(train_generator.class_indices)
class_names = list(train_generator.class_indices.keys())
print(f"Clases detectadas para clasificación: {class_names} ({num_classes} clases)")

# Guardar el mapeo de índice a nombre de clase para usarlo en Blender
class_mapping = {v: k for k, v in train_generator.class_indices.items()}
with open(CLASS_MAPPING_FILE, 'w') as f:
    json.dump(class_mapping, f, indent=4)
print(f"Mapeo de clases guardado en '{CLASS_MAPPING_FILE}'")

# @title Celda 5: Construcción y Entrenamiento del Modelo CNN (Tu Código Original)

# --- CONFIGURACIÓN DE ENTRENAMIENTO ---
EPOCHS = 15

def train_lighting_classifier(base_path, img_height, img_width, batch_size, epochs, model_save_path):
    """
    Entrena un modelo de clasificación para identificar tipos de iluminación.
    """
    # Usaremos ImageDataGenerator para cargar imágenes desde las carpetas
    # y aplicar aumentación de datos simple (re-escalado, validación de split)
    datagen = ImageDataGenerator(
        rescale=1./255, # Normalizar píxeles a 0-1
        validation_split=0.2 # 20% de los datos para validación
    )

    train_generator = datagen.flow_from_directory(
        base_path,
        target_size=(img_height, img_width),
        batch_size=batch_size,
        class_mode='categorical', # Para clasificación multi-clase
        subset='training'
    )

    validation_generator = datagen.flow_from_directory(
        base_path,
        target_size=(img_height, img_width),
        batch_size=batch_size,
        class_mode='categorical',
        subset='validation'
    )

    num_classes = len(train_generator.class_indices)
    class_names = list(train_generator.class_indices.keys())
    print(f"Clases detectadas para clasificación: {class_names}")

    # Guardar el mapeo de índice a nombre de clase para usarlo en Blender
    class_mapping = {v: k for k, v in train_generator.class_indices.items()}
    with open(CLASS_MAPPING_FILE, 'w') as f:
        json.dump(class_mapping, f, indent=4)
    print(f"Mapeo de clases guardado en '{CLASS_MAPPING_FILE}'")


    # --- Construcción del Modelo CNN ---
    model = Sequential([
        Conv2D(16, (3,3), activation='relu', input_shape=(img_height, img_width, 3)),
        MaxPooling2D(pool_size=(2,2)),
        Conv2D(32, (3,3), activation='relu'),
        MaxPooling2D(pool_size=(2,2)),
        Conv2D(64, (3,3), activation='relu'),
        MaxPooling2D(pool_size=(2,2)),
        Flatten(),
        Dense(128, activation='relu'),
        Dropout(0.5), # Regularización para evitar overfitting
        Dense(num_classes, activation='softmax') # Softmax para multi-clase
    ])

    model.compile(optimizer='adam',
                  loss='categorical_crossentropy',
                  metrics=['accuracy'])

    print("Iniciando entrenamiento del modelo...")
    history = model.fit(
        train_generator,
        epochs=epochs,
        validation_data=validation_generator
    )

    # Guarda el modelo entrenado
    model.save(model_save_path)
    print(f"Modelo de clasificación de iluminación guardado en '{model_save_path}'")

    return history

# Llamada a la función de entrenamiento
print(f"Ejecutando train_lighting_classifier con base_path={DATASET_BASE_PATH}, "
      f"IMG_HEIGHT={IMG_HEIGHT}, IMG_WIDTH={IMG_WIDTH}, BATCH_SIZE={BATCH_SIZE}, "
      f"EPOCHS={EPOCHS}, MODEL_SAVE_PATH='{MODEL_SAVE_PATH}'")

# Guardar el objeto history para la visualización posterior
history_object = train_lighting_classifier(DATASET_BASE_PATH, IMG_HEIGHT, IMG_WIDTH, BATCH_SIZE, EPOCHS, MODEL_SAVE_PATH)

# @title Celda 6: Visualización de Resultados del Entrenamiento (Pérdida y Precisión)

print("Visualizando el historial de entrenamiento...")

plt.figure(figsize=(12, 5))

# Gráfico de Pérdida (Loss)
plt.subplot(1, 2, 1)
plt.plot(history_object.history['loss'], label='Pérdida de Entrenamiento')
plt.plot(history_object.history['val_loss'], label='Pérdida de Validación')
plt.title('Pérdida del Modelo (Loss)')
plt.xlabel('Época')
plt.ylabel('Pérdida')
plt.legend()
plt.grid(True)

# Gráfico de Precisión (Accuracy)
plt.subplot(1, 2, 2)
plt.plot(history_object.history['accuracy'], label='Precisión de Entrenamiento')
plt.plot(history_object.history['val_accuracy'], label='Precisión de Validación')
plt.title('Precisión del Modelo (Accuracy)')
plt.xlabel('Época')
plt.ylabel('Precisión')
plt.legend()
plt.grid(True)

plt.tight_layout() # Ajusta el diseño para evitar superposiciones
plt.show()

print("\nGráficos de pérdida y precisión mostrados.")

# Opcional: Descargar el modelo y el mapeo de clases si no se guardaron en Drive
# from google.colab import files
# print("\nSi tu modelo y mapeo no se guardaron en Google Drive, puedes descargarlos aquí:")
# files.download(MODEL_SAVE_PATH)
# files.download(CLASS_MAPPING_FILE)